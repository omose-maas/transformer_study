# transformer_study

以下のページを読みながら、トランスフォーマーを理解しながら実装する。

「作って理解する Transformer / Attention」

https://qiita.com/halhorn/items/c91497522be27bde17ce

1. 実装したら、まずは記事にもあるようなデータセットを使って、トランスフォーマーを使って対話データを学習させてみる。
2. その次に、自前のデータセットを使って対話を学習させてみる

### Transformer.ipynbをクリックすると実装中のコードが確認できます。

### 進捗ログ
2021/02/10
Multi-Head Attentionの前まで進んだ。
